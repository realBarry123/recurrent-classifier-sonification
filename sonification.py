import torch
import numpy as np
from scipy.io import wavfile
from torchvision import datasets, transforms
from model import RClassifier
from utils import *

def mix(audio):
    mix = audio.sum(axis=1)
    mix /= np.max(np.abs(mix))
    return np.int16(mix * 32767)

def sonify(history: torch.Tensor, note_length, fs=44100, do_stereo=True, do_interpolate=False):
    """
    Partially generated by GPT-4o, GPT-5 mini (OpenAI, Jan 2026)
    """
    history = history.cpu().numpy() # (T, V)
    T, V = history.shape
    samples_per_note = int(fs * note_length)

    if do_interpolate:
        freq_samples = interpolate(z_history, samples_per_note).cpu().numpy()
    else:
        freq_samples = np.repeat(history, samples_per_note, axis=0)
    freq_samples = freq_samples.astype(np.float64) #?

    # Previous STAR: phase = 2 * np.pi * np.cumsum(freq_samples, axis=0) / fs
    # Ours: 
    delta = 2 * np.pi * freq_samples / float(fs) # phase increment per sample
    phase = np.cumsum(delta, axis=0) # integrate
    phase = np.mod(phase, 2 * np.pi) # wrap phase

    audio = np.sin(phase)

    if do_stereo:
        T, C = audio.shape

        left_mask = torch.arange(1, 0, -1/C).unsqueeze(0).repeat(T, 1)
        right_mask = torch.ones(C).unsqueeze(0).repeat(T, 1) - left_mask

        # TODO: here arrays go torch -> numpy -> torch
        stereo = [mix(audio * left_mask.numpy()), mix(audio * right_mask.numpy())]
        stereo = torch.tensor(stereo).permute(1, 0)

        return stereo.numpy()
    else:
        wav = mix(audio)
        return wav

if __name__ == "__main__":

    DEVICE = "mps"
    MODEL_NAME = "02-03.1_16x33"
    SONIFICATION_NAME = "02-11.0_confignorm"
    DATA_INDEX = 2
    CONTROL = False

    transform = transforms.ToTensor()
    dataset = datasets.FashionMNIST(root=".", train=True, download=True, transform=transform)

    model, _ = load(f"models/{MODEL_NAME}.pt")
    if CONTROL: 
        model = RClassifier(**model.configs)
    model = model.to(DEVICE)
    model.T = 32

    x, y = dataset[DATA_INDEX]
    x = x.to(DEVICE)
    model(x)

    z_history = model.get_history(layer="z")
    z_history = z_history.squeeze(1)
    # Linear normalization
    z_history = (z_history - torch.min(z_history)) / (torch.max(z_history) - torch.min(z_history)) * 2000 + 50
    histogram(z_history)

    out_history = model.get_history(layer="out")
    out_history = out_history.squeeze(1)
    out_history = torch.nn.functional.softmax(out_history, dim=1)

    wavfile.write(f"{SONIFICATION_NAME}.wav", 44100, sonify(z_history[:, :], 1, do_stereo=True))