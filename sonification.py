import torch
import numpy as np
from scipy.io import wavfile
from torchvision import datasets, transforms
from model import RClassifier
from utils import load, plot_history, interpolate
DEVICE = "mps"

transform = transforms.ToTensor()

dataset = datasets.FashionMNIST(root=".", train=True, download=True, transform=transform)

print(dataset)

model, _ = load("model.pt")
#model = RClassifier(**model.configs)
model = model.to(DEVICE)
model.T = 32

index = 2

x, y = dataset[index]
x = x.to(DEVICE)
_, z_history, out_history = model(x)
z_history = z_history.squeeze(1)
z_history = torch.nn.functional.sigmoid(z_history * 10) * 2000 + 50
# z_history = torch.nn.functional.sigmoid(z_history) * 440
out_history = out_history.squeeze(1)
out_history = torch.nn.functional.softmax(out_history, dim=1)
T, V = z_history.shape
z_history = interpolate(z_history, 8)
print(z_history.shape)
def savie_wavie(history: torch.Tensor, note_length, fs=44100):
    """
    Partially generated by ChatGPT (OpenAI, Jan 2026)
    """
    history = history.cpu().numpy() # (T, V)
    samples_per_note = int(fs * note_length)
    freq_samples = np.repeat(history, samples_per_note, axis=0)

    phase = 2 * np.pi * np.cumsum(freq_samples, axis=0) / fs

    audio = np.sin(phase)
    mix = audio.sum(axis=1)
    mix /= np.max(np.abs(mix))
    wav = np.int16(mix * 32767)

    wavfile.write("interpolate.wav", fs, wav)

savie_wavie(z_history[:, :], 0.06)